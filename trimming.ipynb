{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use James' code for calculating optical flow from Baseline_Optical_Flow_3D_Descriptor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import sqrt, pi, arctan2, cos, sin\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "# Gets the optical flow [<dx,dy>] from two frames\n",
    "def getOpticalFlow(imPrev, imNew):\n",
    "    flow = cv2.calcOpticalFlowFarneback(imPrev, imNew, flow=None, pyr_scale=.5, levels=3, winsize=9, iterations=1, poly_n=3, poly_sigma=1.1, flags=cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "    return flow\n",
    "\n",
    "# Compute the Histogram of Optical Flow (HoF) from the given optical flow\n",
    "def hof(flow, orientations=9, pixels_per_cell=(10, 10),\n",
    "        cells_per_block=(4, 3), normalise=False, motion_threshold=1.):\n",
    "    flow = np.atleast_2d(flow)\n",
    "\n",
    "    if flow.ndim < 3:\n",
    "        raise ValueError(\"Requires dense flow in both directions\")\n",
    "\n",
    "    if normalise:\n",
    "        flow = sqrt(flow)\n",
    "\n",
    "    if flow.dtype.kind == 'u':\n",
    "        flow = flow.astype('float')\n",
    "\n",
    "    gx = np.zeros(flow.shape[:2])\n",
    "    gy = np.zeros(flow.shape[:2])\n",
    "\n",
    "    gx = flow[:,:,1]\n",
    "    gy = flow[:,:,0]\n",
    "\n",
    "    magnitude = sqrt(gx**2 + gy**2)\n",
    "    orientation = arctan2(gy, gx) * (180 / pi) % 180\n",
    "\n",
    "    sy, sx = flow.shape[:2]\n",
    "    cx, cy = pixels_per_cell\n",
    "    bx, by = cells_per_block\n",
    "\n",
    "    n_cellsx = int(np.floor(sx // cx))\n",
    "    n_cellsy = int(np.floor(sy // cy))\n",
    "\n",
    "    orientation_histogram = np.zeros((n_cellsy, n_cellsx, orientations))\n",
    "    subsample = np.index_exp[cy / 2:cy * n_cellsy:cy, cx / 2:cx * n_cellsx:cx]\n",
    "    for i in range(orientations-1):\n",
    "        temp_ori = np.where(orientation < 180 / orientations * (i + 1),\n",
    "                            orientation, -1)\n",
    "        temp_ori = np.where(orientation >= 180 / orientations * i,\n",
    "                            temp_ori, -1)\n",
    "\n",
    "        cond2 = (temp_ori > -1) * (magnitude > motion_threshold)\n",
    "        temp_mag = np.where(cond2, magnitude, 0)\n",
    "\n",
    "        temp_filt = uniform_filter(temp_mag, size=(cy, cx))\n",
    "        orientation_histogram[:, :, i] = temp_filt[subsample]\n",
    "\n",
    "    temp_mag = np.where(magnitude <= motion_threshold, magnitude, 0)\n",
    "\n",
    "    temp_filt = uniform_filter(temp_mag, size=(cy, cx))\n",
    "    orientation_histogram[:, :, -1] = temp_filt[subsample]\n",
    "\n",
    "    n_blocksx = (n_cellsx - bx) + 1\n",
    "    n_blocksy = (n_cellsy - by) + 1\n",
    "    normalised_blocks = np.zeros((n_blocksy, n_blocksx,\n",
    "                                  by, bx, orientations))\n",
    "\n",
    "    for x in range(n_blocksx):\n",
    "        for y in range(n_blocksy):\n",
    "            block = orientation_histogram[y:y+by, x:x+bx, :]\n",
    "            eps = 1e-5\n",
    "            normalised_blocks[y, x, :] = block / sqrt(block.sum()**2 + eps)\n",
    "\n",
    "    return normalised_blocks.ravel()\n",
    "\n",
    "FIXED_WIDTH = 160\n",
    "FIXED_HEIGHT = 120\n",
    "def normalizeFrame(frame_original):\n",
    "    frame_gray = cv2.cvtColor(frame_original,cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray_resized = cv2.resize(frame_gray, (FIXED_WIDTH, FIXED_HEIGHT))\n",
    "    return frame_gray_resized\n",
    "\n",
    "# get the Histogram of Optical Flow from two images\n",
    "def getHoF(frame1, frame2):\n",
    "    flow = getOpticalFlow(frame1, frame2)\n",
    "    return hof(flow, pixels_per_cell=(20,20), cells_per_block=(5,5))\n",
    "\n",
    "# get the Histogram of Optical Flows of a video grouped sequentially in a 1D array\n",
    "def getSequentialHoF(video_path):\n",
    "    hofs = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret1, frame1 = cap.read()\n",
    "    frame1 = normalizeFrame(frame1)\n",
    "    while(cap.isOpened()):\n",
    "        ret2, frame2 = cap.read()\n",
    "        if ret2 == True:\n",
    "            frame2 = normalizeFrame(frame2)\n",
    "            hof_array = getHoF(frame1, frame2)\n",
    "            hofs = np.concatenate((hofs, hof_array),axis=0)\n",
    "            frame1 = frame2\n",
    "        else:\n",
    "            break\n",
    "    return hofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This descriptor returns features of different length, depending on the length of the input videos. Padding the HoF feature vector of each video to the length of the largest video does not give great accuracy: another solution to this problem would be to trim all videos to the size of the smallest video in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Determine the length in frames of the shortest video in the provided dataset\n",
    "def shortest(data_dir):\n",
    "    # get list of files in the directory. directory should be flat with only video files in it\n",
    "    files = os.listdir(data_dir)\n",
    "    \n",
    "    # Find the length of the shortest video (in frames)\n",
    "    shortestLen = sys.maxint\n",
    "    for i in range(len(files)):\n",
    "        cap = cv2.VideoCapture(data_dir+'/'+files[i])\n",
    "        \n",
    "        # This line tries to get the length of the video from the header.\n",
    "        length = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))\n",
    "        if length > 0 and length < shortestLen:\n",
    "            #if length < shortestLen:\n",
    "            shortestLen = length\n",
    "            # If it didn't work, we need to count the frames\n",
    "        else:\n",
    "            length = 0\n",
    "            # Using grab here as an optimistic estimate (assuming here all grabbed frames can be decoded)\n",
    "            while (cap.grab()): length += 1\n",
    "            if length < shortestLen: shortestLen = length\n",
    "        \n",
    "        #print(length)\n",
    "        cap.release()\n",
    "        \n",
    "    return shortestLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try running this on the walking video dataset from http://www.nada.kth.se/cvap/actions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548\n"
     ]
    }
   ],
   "source": [
    "print (len(os.listdir('./hof/walk')))\n",
    "print (shortest('./hof/walk'))\n",
    "# files = os.listdir('./hof/walk')\n",
    "# #cap = cv2.VideoCapture('./hof/walk/'+files[0])\n",
    "# cap = cv2.VideoCapture('/Users/kaveenherath/Documents/github/project-okulo/hof/run/veoh_harold_and_kumar_run_f_nm_np2_fr_med_6.mp4')\n",
    "# cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, use this amount of frames from the middle of each video as a representative sample of that video to calculate HoF feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get the Histogram of Optical Flows of a video grouped sequentially in a 1D array\n",
    "# use only the specified amount of frames, from the middle of the video\n",
    "def getSequentialHoFMiddle(video_path, frames):\n",
    "    hofs = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # I'm going to assume this works once stuff is fixed\n",
    "    startIdx = (length - frames)/2\n",
    "    \n",
    "    # skip through beginning unneeded frames\n",
    "    frameNum = 0\n",
    "    while (frameNum < startIdx):\n",
    "        cap.grab()\n",
    "        frameNum += 1\n",
    "    frameNum = 0\n",
    "    \n",
    "    # Calculate HoF from necessary frames\n",
    "    ret1, frame1 = cap.read()\n",
    "    frame1 = normalizeFrame(frame1)\n",
    "    while(frameNum < frames):\n",
    "        ret2, frame2 = cap.read()\n",
    "        if ret2 == True:\n",
    "            frame2 = normalizeFrame(frame2)\n",
    "            hof_array = getHoF(frame1, frame2)\n",
    "            hofs = np.concatenate((hofs, hof_array),axis=0)\n",
    "            frame1 = frame2\n",
    "            frameNum += 1\n",
    "        else:\n",
    "            break\n",
    "    return hofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, create features from trimmed videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import os\n",
    "\n",
    "# Collect the file path of all the running and walking videos,\n",
    "# we will only be using these 2 classes\n",
    "RUN_DIR = \"./hof/walk\"\n",
    "RUN_FILES = os.listdir(RUN_DIR)\n",
    "RUN_FILES = [RUN_DIR + f for f in RUN_FILES]\n",
    "WALK_DIR = \"./hof/run\"\n",
    "WALK_FILES = os.listdir(WALK_DIR)\n",
    "WALK_FILES = [WALK_DIR + f for f in WALK_FILES]\n",
    "\n",
    "# Use equal number of data from each class\n",
    "nc = min(len(RUN_FILES), len(WALK_FILES))\n",
    "print \"nc:\", nc\n",
    "RUN_FILES = RUN_FILES[0:nc]\n",
    "WALK_FILES = WALK_FILES[0:nc]\n",
    "\n",
    "RATIO = 0.9\n",
    "offset = int(np.floor(nc*RATIO))\n",
    "print \"offset:\", offset\n",
    "\n",
    "# Split test and training at a ratio of 1:9\n",
    "train_files = RUN_FILES[0:offset] + WALK_FILES[0:offset]\n",
    "test_files = RUN_FILES[offset:nc] + WALK_FILES[offset:nc]\n",
    "\n",
    "# Put the labels in vectors\n",
    "train_labels = np.zeros(offset*2, int)\n",
    "train_labels[0:offset] = 1 #RUN=1\n",
    "train_labels[offset:offset*2] = 2 #WALK=2\n",
    "\n",
    "test_len = nc-offset\n",
    "test_labels = np.zeros(test_len*2, int)\n",
    "test_labels[0:test_len] = 1 #RUN=1\n",
    "test_labels[test_len:test_len*2] = 2 #WALK=2\n",
    "\n",
    "print \"train files:\", len(train_files)\n",
    "print \"train labels:\", len(train_labels)\n",
    "print \"test files:\", len(test_files)\n",
    "print \"test labels:\", len(test_labels)\n",
    "\n",
    "numFrames = min(shortestLen('./hof/walk'), shortestLen('./hof/run'))\n",
    "train = [getSequentialHoFMiddle(p, numFrames) for p in train_files]\n",
    "test = [getSequentialHoFMiddle(p, numFrames) for p in test_files]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create and test SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train, train_labels)\n",
    "predict = clf.predict(test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(predict, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create and test decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(train, train_labels)\n",
    "predict = tree_clf.predict(test)\n",
    "print(metrics.accuracy_score(predict, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create and test random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rf_clf = ensemble.RandomForestClassifier()\n",
    "rf_clf.fit(train, train_labels)\n",
    "predict = rf_clf.predict(test)\n",
    "print(metrics.accuracy_score(predict, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create and test logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lr_clf = linear_model.LogisticRegression()\n",
    "lr_clf.fit(train, train_labels)\n",
    "predict = lr_clf.predict(test)\n",
    "print(metrics.accuracy_score(predict, test_labels))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
