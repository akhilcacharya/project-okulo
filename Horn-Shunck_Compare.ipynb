{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define method for calculating optical flow using the Horn-Shunck algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scipy import signal\n",
    "import numpy\n",
    "\n",
    "X_FILTER = [[-1, 1], [-1, 1]]\n",
    "Y_FILTER = [[-1, -1], [1, 1]]\n",
    "T_FILTER = [[-1, -1],[-1, -1]]\n",
    "LAP_FILTER = [[0, -0.25, 0], [-0.25, 1, -0.25], [0, -0.25, 0]]\n",
    "\n",
    "# Calculate optical flow between two images (frames) using the Horn-Shunck algorithm\n",
    "#   alpha is a parameter\n",
    "#   k is the number of iterations until 'convergence' (lazy lazy...)\n",
    "def calcflowHS(frame1, frame2, alpha, k):\n",
    "    # Calculate derivatives over images\n",
    "    #   filter over each frame and sum them for change between frames\n",
    "    fx = signal.convolve(frame1, X_FILTER) + signal.convolve(frame2, X_FILTER)\n",
    "    fy = signal.convolve(frame1, Y_FILTER) + signal.convolve(frame2, Y_FILTER)\n",
    "    ft = signal.convolve(frame1, T_FILTER) + signal.convolve(frame2, -T_FILTER)\n",
    "\n",
    "    # Initialize flows at zero\n",
    "    u = np.zeros(frame1.shape[0], frame1.shape[1])\n",
    "    v = np.zeros(frame2.shape[0], frame2.shape[1])\n",
    "\n",
    "    # Iterate until error measure specifies convergence\n",
    "    #   (I am being lazy with the error measure for now and just performing a set num iterations)\n",
    "    d = alpha + fx**2 + fy**2\n",
    "    for i in range(k):\n",
    "        #   Calculate averages across last iteration's estimate\n",
    "        u_avg = signal.convolve(u, LAP_FILTER)\n",
    "        v_avg = signal.convolve(v, LAP_FILTER)\n",
    "\n",
    "        p = numpy.dot(fx, u_avg) + numpy.dot(fy, v_avg) + ft\n",
    "\n",
    "        #   Calculate new estimates\n",
    "        u = u_avg - numpy.dot(fx, numpy.divide(p, d))\n",
    "        v = v_avg - numpy.dot(fy, numpy.divide(p, d))\n",
    "\n",
    "    return (u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use James' code for HoF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import sqrt, pi, arctan2, cos, sin\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "# Gets the optical flow [<dx,dy>] from two frames\n",
    "def getOpticalFlow(imPrev, imNew):\n",
    "    flow = cv2.calcOpticalFlowFarneback(imPrev, imNew, flow=None, pyr_scale=.5, levels=3, winsize=9, iterations=1, poly_n=3, poly_sigma=1.1, flags=cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "    return flow\n",
    "\n",
    "# Compute the Histogram of Optical Flow (HoF) from the given optical flow\n",
    "def hof(flow, orientations=9, pixels_per_cell=(10, 10),\n",
    "        cells_per_block=(4, 3), normalise=False, motion_threshold=1.):\n",
    "    flow = np.atleast_2d(flow)\n",
    "\n",
    "    if flow.ndim < 3:\n",
    "        raise ValueError(\"Requires dense flow in both directions\")\n",
    "\n",
    "    if normalise:\n",
    "        flow = sqrt(flow)\n",
    "\n",
    "    if flow.dtype.kind == 'u':\n",
    "        flow = flow.astype('float')\n",
    "\n",
    "    gx = np.zeros(flow.shape[:2])\n",
    "    gy = np.zeros(flow.shape[:2])\n",
    "\n",
    "    gx = flow[:,:,1]\n",
    "    gy = flow[:,:,0]\n",
    "\n",
    "    magnitude = sqrt(gx**2 + gy**2)\n",
    "    orientation = arctan2(gy, gx) * (180 / pi) % 180\n",
    "\n",
    "    sy, sx = flow.shape[:2]\n",
    "    cx, cy = pixels_per_cell\n",
    "    bx, by = cells_per_block\n",
    "\n",
    "    n_cellsx = int(np.floor(sx // cx))\n",
    "    n_cellsy = int(np.floor(sy // cy))\n",
    "\n",
    "    orientation_histogram = np.zeros((n_cellsy, n_cellsx, orientations))\n",
    "    subsample = np.index_exp[cy / 2:cy * n_cellsy:cy, cx / 2:cx * n_cellsx:cx]\n",
    "    for i in range(orientations-1):\n",
    "        temp_ori = np.where(orientation < 180 / orientations * (i + 1),\n",
    "                            orientation, -1)\n",
    "        temp_ori = np.where(orientation >= 180 / orientations * i,\n",
    "                            temp_ori, -1)\n",
    "\n",
    "        cond2 = (temp_ori > -1) * (magnitude > motion_threshold)\n",
    "        temp_mag = np.where(cond2, magnitude, 0)\n",
    "\n",
    "        temp_filt = uniform_filter(temp_mag, size=(cy, cx))\n",
    "        orientation_histogram[:, :, i] = temp_filt[subsample]\n",
    "\n",
    "    temp_mag = np.where(magnitude <= motion_threshold, magnitude, 0)\n",
    "\n",
    "    temp_filt = uniform_filter(temp_mag, size=(cy, cx))\n",
    "    orientation_histogram[:, :, -1] = temp_filt[subsample]\n",
    "\n",
    "    n_blocksx = (n_cellsx - bx) + 1\n",
    "    n_blocksy = (n_cellsy - by) + 1\n",
    "    normalised_blocks = np.zeros((n_blocksy, n_blocksx,\n",
    "                                  by, bx, orientations))\n",
    "\n",
    "    for x in range(n_blocksx):\n",
    "        for y in range(n_blocksy):\n",
    "            block = orientation_histogram[y:y+by, x:x+bx, :]\n",
    "            eps = 1e-5\n",
    "            normalised_blocks[y, x, :] = block / sqrt(block.sum()**2 + eps)\n",
    "\n",
    "    return normalised_blocks.ravel()\n",
    "\n",
    "FIXED_WIDTH = 160\n",
    "FIXED_HEIGHT = 120\n",
    "def normalizeFrame(frame_original):\n",
    "    frame_gray = cv2.cvtColor(frame_original,cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray_resized = cv2.resize(frame_gray, (FIXED_WIDTH, FIXED_HEIGHT))\n",
    "    return frame_gray_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine HoF descriptor method to be able to use either flow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the Histogram of Optical Flows of a video grouped sequentially in a 1D array\n",
    "def getSequentialHoF(video_path, hs):\n",
    "    hofs = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret1, frame1 = cap.read()\n",
    "    frame1 = normalizeFrame(frame1)\n",
    "    while(cap.isOpened()):\n",
    "        ret2, frame2 = cap.read()\n",
    "        if ret2 == True:\n",
    "            frame2 = normalizeFrame(frame2)\n",
    "            \n",
    "            # Gut original getHoF method and put it here, with option to switch flow types\n",
    "            flow = calcFlowHS(frame1, frame2, 1, 100) if hs else getOpticalFlow(frame1, frame2)\n",
    "            hof_array = hof(flow, pixels_per_cell=(20,20), cells_per_block=(5,5))\n",
    "            \n",
    "            hofs = np.concatenate((hofs, hof_array),axis=0)\n",
    "            frame1 = frame2\n",
    "        else:\n",
    "            break\n",
    "    return hofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nc: 232\n",
      "offset: 208\n",
      "train files: 416\n",
      "train labels: 416\n",
      "test files: 48\n",
      "test labels: 48\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/build/opencv/src/opencv-3.2.0/modules/imgproc/src/color.cpp:9748: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b0fca76ee1ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"test labels:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrainHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetSequentialHoF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mtestHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetSequentialHoF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetSequentialHoF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-9a73caf32303>\u001b[0m in \u001b[0;36mgetSequentialHoF\u001b[0;34m(video_path, hs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mret1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mframe1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizeFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mret2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-072254978457>\u001b[0m in \u001b[0;36mnormalizeFrame\u001b[0;34m(frame_original)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mFIXED_HEIGHT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalizeFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mframe_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_original\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mframe_gray_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFIXED_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIXED_HEIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mframe_gray_resized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /build/opencv/src/opencv-3.2.0/modules/imgproc/src/color.cpp:9748: error: (-215) scn == 3 || scn == 4 in function cvtColor\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import os\n",
    "\n",
    "# Collect the file path of all the running and walking videos,\n",
    "# we will only be using these 2 classes\n",
    "RUN_DIR = \"./hof/walk\"\n",
    "RUN_FILES = os.listdir(RUN_DIR)\n",
    "RUN_FILES = [RUN_DIR + f for f in RUN_FILES]\n",
    "WALK_DIR = \"./hof/run\"\n",
    "WALK_FILES = os.listdir(WALK_DIR)\n",
    "WALK_FILES = [WALK_DIR + f for f in WALK_FILES]\n",
    "\n",
    "# Use equal number of data from each class\n",
    "nc = min(len(RUN_FILES), len(WALK_FILES))\n",
    "print \"nc:\", nc\n",
    "RUN_FILES = RUN_FILES[0:nc]\n",
    "WALK_FILES = WALK_FILES[0:nc]\n",
    "\n",
    "RATIO = 0.9\n",
    "offset = int(np.floor(nc*RATIO))\n",
    "print \"offset:\", offset\n",
    "\n",
    "# Split test and training at a ratio of 1:9\n",
    "train_files = RUN_FILES[0:offset] + WALK_FILES[0:offset]\n",
    "test_files = RUN_FILES[offset:nc] + WALK_FILES[offset:nc]\n",
    "\n",
    "# Put the labels in vectors\n",
    "train_labels = np.zeros(offset*2, int)\n",
    "train_labels[0:offset] = 1 #RUN=1\n",
    "train_labels[offset:offset*2] = 2 #WALK=2\n",
    "\n",
    "test_len = nc-offset\n",
    "test_labels = np.zeros(test_len*2, int)\n",
    "test_labels[0:test_len] = 1 #RUN=1\n",
    "test_labels[test_len:test_len*2] = 2 #WALK=2\n",
    "\n",
    "print \"train files:\", len(train_files)\n",
    "print \"train labels:\", len(train_labels)\n",
    "print \"test files:\", len(test_files)\n",
    "print \"test labels:\", len(test_labels)\n",
    "\n",
    "trainHS = [getSequentialHoF(p, True) for p in train_files]\n",
    "testHS = [getSequentialHoF(p, True) for p in test_files]\n",
    "train = [getSequentialHoF(p, False) for p in train_files]\n",
    "test = [getSequentialHoF(p, False) for p in test_files]\n",
    "\n",
    "max_width = max(np.array([len(i) for i in train]).max(),np.array([len(i) for i in test]).max())\n",
    "def numpy_fillna(data, width):\n",
    "    # Get lengths of each row of data\n",
    "    lens = np.array([len(i) for i in data])\n",
    "\n",
    "    # Mask of valid places in each row\n",
    "    mask = np.arange(width) < lens[:,None]\n",
    "\n",
    "    # Setup output array and put elements from data into masked positions\n",
    "    out = np.zeros(mask.shape, dtype=data.dtype)\n",
    "    out[mask] = np.concatenate(data)\n",
    "    return out\n",
    "\n",
    "train_pad = numpy_fillna(np.array(train), max_width)\n",
    "test_pad = numpy_fillna(np.array(test), max_width)\n",
    "train_pad_HS = numpy_fillna(np.array(train), max_width)\n",
    "test_pad_HS = numpy_fillna(np.array(test), max_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and test SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_pad, train_labels)\n",
    "predict = clf.predict(test_pad)\n",
    "\n",
    "from sklearn import metrics\n",
    "print 'cv2: %f' % metrics.accuracy_score(predict, test_labels)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_pad_HS, train_labels)\n",
    "predict = clf.predict(test_pad_HS)\n",
    "print 'MyHS: %f' % metrics.accuracy_score(predict, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and test decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(train_pad, train_labels)\n",
    "predict = tree_clf.predict(test_pad)\n",
    "print 'cv2: %f' % metrics.accuracy_score(predict, test_labels)\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(train_pad_HS, train_labels)\n",
    "predict = tree_clf.predict(test_pad_HS)\n",
    "print 'MyHS: %f' % metrics.accuracy_score(predict, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and test random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rf_clf = ensemble.RandomForestClassifier()\n",
    "rf_clf.fit(train_pad, train_labels)\n",
    "predict = rf_clf.predict(test_pad)\n",
    "print 'cv2: %f' % metrics.accuracy_score(predict, test_labels)\n",
    "\n",
    "rf_clf = ensemble.RandomForestClassifier()\n",
    "rf_clf.fit(train_pad_HS, train_labels)\n",
    "predict = rf_clf.predict(test_pad_HS)\n",
    "print 'MyHS: %f' % metrics.accuracy_score(predict, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and test logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lr_clf = linear_model.LogisticRegression()\n",
    "lr_clf.fit(train_pad, train_labels)\n",
    "predict = lr_clf.predict(test_pad)\n",
    "print 'cv2: %f' % metrics.accuracy_score(predict, test_labels)\n",
    "\n",
    "lr_clf = linear_model.LogisticRegression()\n",
    "lr_clf.fit(train_pad_HS, train_labels)\n",
    "predict = lr_clf.predict(test_pad_HS)\n",
    "print 'MyHS: %f' % metrics.accuracy_score(predict, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
